"""
ADDIE Agent: StateGraph 기반 순차적 교수설계 에이전트

ADDIE 모형의 선형적/순차적 프로세스를 LangGraph StateGraph로 구현합니다.
[START] → [Analysis] → [Design] → [Development] → [Implementation] → [Evaluation] → [END]
"""

import os
from datetime import datetime
from typing import Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

from langgraph.graph import StateGraph, END

from addie_agent.state import (
    ADDIEState,
    ScenarioInput,
    ToolCall,
    create_initial_state,
)
from addie_agent.tools import (
    # Analysis (요구분석, 학습자분석, 환경분석, 과제분석)
    analyze_needs,
    analyze_learner,
    analyze_context,
    analyze_task,
    # Design (목표명세화, 평가도구, 교수전략)
    design_objectives,
    design_assessment,
    design_strategy,
    # Development (레슨플랜, 교수자료)
    create_lesson_plan,
    create_materials,
    # Implementation (실행계획, 유지관리)
    create_implementation_plan,
    create_maintenance_plan,
    # Evaluation (퀴즈, 루브릭, 성과평가)
    create_quiz_items,
    create_rubric,
    create_program_evaluation,
)


def _parse_class_size(value: Any) -> Optional[int]:
    """class_size 값을 정수로 변환 (문자열 처리 포함)"""
    if value is None:
        return None
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        # "소규모(1-10명)" → 5, "30명" → 30 등 숫자 추출
        import re
        numbers = re.findall(r'\d+', value)
        if numbers:
            # 범위인 경우 중간값 사용
            if len(numbers) >= 2:
                return (int(numbers[0]) + int(numbers[1])) // 2
            return int(numbers[0])
    return None


class ADDIEAgent:
    """
    ADDIE 모형 기반 순차적 교수설계 에이전트

    LangGraph StateGraph를 사용하여 ADDIE 5단계를 순차적으로 실행합니다.
    각 단계의 산출물이 다음 단계의 입력으로 활용됩니다.
    """

    def __init__(
        self,
        model: str = "solar-mini",
        temperature: float = 0.7,
        debug: bool = False,
    ):
        self.model = model
        self.temperature = temperature
        self.debug = debug

        # 환경 변수 설정
        os.environ["ADDIE_MODEL"] = model

        # StateGraph 빌드
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        """선형 StateGraph 빌드"""
        # StateGraph 생성
        workflow = StateGraph(ADDIEState)

        # 노드 추가
        workflow.add_node("analysis", self._analysis_node)
        workflow.add_node("design", self._design_node)
        workflow.add_node("development", self._development_node)
        workflow.add_node("implementation", self._implementation_node)
        workflow.add_node("evaluation", self._evaluation_node)

        # 엣지 추가 (선형 워크플로우)
        workflow.set_entry_point("analysis")
        workflow.add_edge("analysis", "design")
        workflow.add_edge("design", "development")
        workflow.add_edge("development", "implementation")
        workflow.add_edge("implementation", "evaluation")
        workflow.add_edge("evaluation", END)

        return workflow.compile()

    def _log(self, message: str):
        """디버그 로깅"""
        if self.debug:
            print(f"[ADDIE] {message}")

    def _record_tool_call(
        self,
        state: ADDIEState,
        tool_name: str,
        args: dict,
        result: str,
        start_time: datetime,
    ) -> ToolCall:
        """도구 호출 기록"""
        end_time = datetime.now()
        duration_ms = int((end_time - start_time).total_seconds() * 1000)

        tool_call = ToolCall(
            step=len(state.get("tool_calls", [])) + 1,
            tool=tool_name,
            args=args,
            result=result,
            timestamp=start_time.isoformat(),
            duration_ms=duration_ms,
            success=True,
        )

        return tool_call

    def _analysis_node(self, state: ADDIEState) -> dict:
        """Analysis 단계 노드"""
        self._log("Analysis 단계 시작")
        scenario = state["scenario"]
        context = scenario.get("context", {})
        tool_calls = state.get("tool_calls", [])
        reasoning_steps = state.get("reasoning_steps", [])
        errors = state.get("errors", [])

        reasoning_steps.append("Step 1: Analysis 단계 - 요구분석, 학습자, 환경, 과제 분석 (병렬)")

        # Analysis 4단계 병렬 실행 (#73 성능 최적화)
        parallel_start_time = datetime.now()
        needs_result = {}
        learner_result = {}
        context_result = {}
        task_result = {}

        def invoke_needs():
            return analyze_needs.invoke({
                "learning_goals": scenario.get("learning_goals", []),
                "current_state": context.get("prior_knowledge"),
                "desired_state": scenario.get("expected_outcomes", [None])[0] if scenario.get("expected_outcomes") else None,
                "performance_gap": context.get("performance_gap"),
            })

        def invoke_learner():
            return analyze_learner.invoke({
                "target_audience": context.get("target_audience", "일반 학습자"),
                "prior_knowledge": context.get("prior_knowledge"),
                "additional_context": context.get("additional_context"),
            })

        def invoke_context():
            return analyze_context.invoke({
                "learning_environment": context.get("learning_environment", "미지정"),
                "duration": context.get("duration", "미지정"),
                "class_size": _parse_class_size(context.get("class_size")),
                "budget": scenario.get("constraints", {}).get("budget"),
                "resources": scenario.get("constraints", {}).get("resources"),
            })

        def invoke_task():
            return analyze_task.invoke({
                "learning_goals": scenario.get("learning_goals", []),
                "domain": scenario.get("domain"),
                "difficulty": scenario.get("difficulty"),
            })

        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(invoke_needs): "needs",
                executor.submit(invoke_learner): "learner",
                executor.submit(invoke_context): "context",
                executor.submit(invoke_task): "task",
            }
            for future in as_completed(futures):
                analysis_type = futures[future]
                try:
                    result = future.result()
                    if analysis_type == "needs":
                        needs_result = result
                        tool_calls.append(self._record_tool_call(
                            state, "analyze_needs",
                            {"learning_goals": scenario.get("learning_goals", [])},
                            f"요구분석 완료: {len(needs_result.get('training_needs', []))}개 교육 니즈 도출",
                            parallel_start_time,
                        ))
                    elif analysis_type == "learner":
                        learner_result = result
                        tool_calls.append(self._record_tool_call(
                            state, "analyze_learner",
                            {"target_audience": context.get("target_audience", "")},
                            f"학습자 분석 완료: {len(learner_result.get('characteristics', []))}개 특성",
                            parallel_start_time,
                        ))
                    elif analysis_type == "context":
                        context_result = result
                        tool_calls.append(self._record_tool_call(
                            state, "analyze_context",
                            {"learning_environment": context.get("learning_environment", "")},
                            f"환경 분석 완료: {len(context_result.get('constraints', []))}개 제약조건",
                            parallel_start_time,
                        ))
                    elif analysis_type == "task":
                        task_result = result
                        tool_calls.append(self._record_tool_call(
                            state, "analyze_task",
                            {"learning_goals": scenario.get("learning_goals", [])},
                            f"과제 분석 완료: {len(task_result.get('main_topics', []))}개 주제",
                            parallel_start_time,
                        ))
                except Exception as e:
                    errors.append(f"analyze_{analysis_type} 실패: {str(e)}")

        # LLM 응답에 누락된 priority_matrix 보완 (A-4)
        if needs_result and "priority_matrix" not in needs_result:
            training_needs = needs_result.get("training_needs", [])
            needs_result["priority_matrix"] = {
                "high_urgency_high_impact": training_needs[:2] if len(training_needs) >= 2 else training_needs,
                "high_urgency_low_impact": [training_needs[2]] if len(training_needs) > 2 else [],
                "low_urgency_high_impact": ["심화 역량 개발"],
                "low_urgency_low_impact": ["선택적 자기계발 과정"],
            }

        self._log(f"Analysis 완료: needs={len(needs_result.get('training_needs', []))}, learner={len(learner_result.get('characteristics', []))}, context={len(context_result.get('constraints', []))}, task={len(task_result.get('main_topics', []))}")

        return {
            "analysis_result": {
                "needs_analysis": needs_result,
                "learner_analysis": learner_result,
                "context_analysis": context_result,
                "task_analysis": task_result,
            },
            "current_phase": "design",
            "tool_calls": tool_calls,
            "reasoning_steps": reasoning_steps,
            "errors": errors,
        }

    def _design_node(self, state: ADDIEState) -> dict:
        """Design 단계 노드"""
        self._log("Design 단계 시작")
        scenario = state["scenario"]
        context = scenario.get("context", {})
        analysis = state.get("analysis_result", {})
        task_analysis = analysis.get("task_analysis", {})
        tool_calls = state.get("tool_calls", [])
        reasoning_steps = state.get("reasoning_steps", [])
        errors = state.get("errors", [])

        reasoning_steps.append("Step 2: Design 단계 - 학습 목표, 평가 계획, 교수 전략 설계")

        # 1. 학습 목표 설계
        start_time = datetime.now()
        try:
            objectives_result = design_objectives.invoke({
                "learning_goals": scenario.get("learning_goals", []),
                "target_audience": context.get("target_audience", "일반 학습자"),
                "difficulty": scenario.get("difficulty"),
            })
            tool_calls.append(self._record_tool_call(
                state, "design_objectives",
                {"learning_goals": scenario.get("learning_goals", [])},
                f"학습 목표 설계 완료: {len(objectives_result)}개",
                start_time,
            ))
        except Exception as e:
            errors.append(f"design_objectives 실패: {str(e)}")
            objectives_result = []

        # 2. 평가 계획 수립
        start_time = datetime.now()
        try:
            assessment_result = design_assessment.invoke({
                "objectives": objectives_result,
                "duration": context.get("duration", "미지정"),
                "learning_environment": context.get("learning_environment", "미지정"),
            })
            tool_calls.append(self._record_tool_call(
                state, "design_assessment",
                {"objectives_count": len(objectives_result)},
                f"평가 계획 수립 완료",
                start_time,
            ))
        except Exception as e:
            errors.append(f"design_assessment 실패: {str(e)}")
            assessment_result = {}

        # 3. 교수 전략 설계
        start_time = datetime.now()
        main_topics = task_analysis.get("main_topics", scenario.get("learning_goals", []))
        try:
            strategy_result = design_strategy.invoke({
                "main_topics": main_topics,
                "target_audience": context.get("target_audience", "일반 학습자"),
                "duration": context.get("duration", "미지정"),
                "learning_environment": context.get("learning_environment", "미지정"),
            })
            tool_calls.append(self._record_tool_call(
                state, "design_strategy",
                {"main_topics": main_topics},
                f"교수 전략 설계 완료: {len(strategy_result.get('sequence', []))}개 Event",
                start_time,
            ))
        except Exception as e:
            errors.append(f"design_strategy 실패: {str(e)}")
            strategy_result = {}

        self._log(f"Design 완료: objectives={len(objectives_result)}, events={len(strategy_result.get('sequence', []))}")

        return {
            "design_result": {
                "learning_objectives": objectives_result,
                "assessment_plan": assessment_result,
                "instructional_strategy": strategy_result,
            },
            "current_phase": "development",
            "tool_calls": tool_calls,
            "reasoning_steps": reasoning_steps,
            "errors": errors,
        }

    def _development_node(self, state: ADDIEState) -> dict:
        """Development 단계 노드"""
        self._log("Development 단계 시작")
        scenario = state["scenario"]
        context = scenario.get("context", {})
        analysis = state.get("analysis_result", {})
        design = state.get("design_result", {})
        task_analysis = analysis.get("task_analysis", {})
        tool_calls = state.get("tool_calls", [])
        reasoning_steps = state.get("reasoning_steps", [])
        errors = state.get("errors", [])

        reasoning_steps.append("Step 3: Development 단계 - 레슨 플랜, 학습 자료 개발")

        objectives = design.get("learning_objectives", [])
        strategy = design.get("instructional_strategy", {})
        main_topics = task_analysis.get("main_topics", scenario.get("learning_goals", []))

        # 1. 레슨 플랜 생성
        start_time = datetime.now()
        try:
            lesson_plan_result = create_lesson_plan.invoke({
                "objectives": objectives,
                "instructional_strategy": strategy,
                "duration": context.get("duration", "미지정"),
                "main_topics": main_topics,
            })
            tool_calls.append(self._record_tool_call(
                state, "create_lesson_plan",
                {"duration": context.get("duration", "")},
                f"레슨 플랜 생성 완료: {len(lesson_plan_result.get('modules', []))}개 모듈",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_lesson_plan 실패: {str(e)}")
            lesson_plan_result = {}

        # 2. 학습 자료 생성
        start_time = datetime.now()
        try:
            materials_result = create_materials.invoke({
                "lesson_plan": lesson_plan_result,
                "learning_environment": context.get("learning_environment", "미지정"),
                "target_audience": context.get("target_audience", "일반 학습자"),
            })
            tool_calls.append(self._record_tool_call(
                state, "create_materials",
                {"lesson_plan_modules": len(lesson_plan_result.get("modules", []))},
                f"학습 자료 생성 완료: {len(materials_result)}개",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_materials 실패: {str(e)}")
            materials_result = []

        # LLM 응답에 누락된 storyboard 보완 (D-18)
        if materials_result:
            default_storyboard = [
                {"frame_number": 1, "screen_title": "도입 화면", "visual_description": "교육 제목과 로고 표시", "audio_narration": "교육에 오신 것을 환영합니다.", "interaction": "시작 버튼 클릭", "notes": "배경음악 페이드인"},
                {"frame_number": 2, "screen_title": "학습 목표", "visual_description": "학습 목표 목록 애니메이션", "audio_narration": "오늘 학습할 내용을 확인합니다.", "interaction": "자동 진행", "notes": "목표별 순차 표시"},
            ]
            for material in materials_result:
                if material.get("type") in ["PPT", "동영상"] and "storyboard" not in material:
                    material["storyboard"] = default_storyboard

        self._log(f"Development 완료: modules={len(lesson_plan_result.get('modules', []))}, materials={len(materials_result)}")

        # 출력 구조: 루브릭 항목과 일치하도록 명시적 필드명 사용
        # Item 19: 학습자용 자료 개발 - materials를 learner_materials로 명시
        # Item 20: 교수자용 매뉴얼 - facilitator_guide (implementation에서 생성)
        # Item 21: 운영자용 매뉴얼 - operator_guide (implementation에서 생성)
        # Item 22: 평가 도구·문항 - evaluation에서 생성
        return {
            "development_result": {
                "lesson_plan": lesson_plan_result,
                "learner_materials": materials_result,  # Item 19: 학습자용 자료 개발
                "materials": materials_result,  # 기존 호환성 유지
            },
            "current_phase": "implementation",
            "tool_calls": tool_calls,
            "reasoning_steps": reasoning_steps,
            "errors": errors,
        }

    def _implementation_node(self, state: ADDIEState) -> dict:
        """Implementation 단계 노드"""
        self._log("Implementation 단계 시작")
        scenario = state["scenario"]
        context = scenario.get("context", {})
        development = state.get("development_result", {})
        tool_calls = state.get("tool_calls", [])
        reasoning_steps = state.get("reasoning_steps", [])
        errors = state.get("errors", [])

        reasoning_steps.append("Step 4: Implementation 단계 - 실행 계획 및 유지관리 계획 수립")

        lesson_plan = development.get("lesson_plan", {})

        # 실행 계획 생성
        start_time = datetime.now()
        try:
            implementation_result = create_implementation_plan.invoke({
                "lesson_plan": lesson_plan,
                "learning_environment": context.get("learning_environment", "미지정"),
                "target_audience": context.get("target_audience", "일반 학습자"),
                "class_size": _parse_class_size(context.get("class_size")),
            })
            fg_len = len(implementation_result.get("facilitator_guide", ""))
            lg_len = len(implementation_result.get("learner_guide", ""))
            tool_calls.append(self._record_tool_call(
                state, "create_implementation_plan",
                {"learning_environment": context.get("learning_environment", "")},
                f"실행 계획 완료: facilitator_guide={fg_len}자, learner_guide={lg_len}자",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_implementation_plan 실패: {str(e)}")
            implementation_result = {}

        # LLM 응답에 누락된 필드 보완 (Dev-21, I-24, I-26)
        if implementation_result:
            env_lower = context.get("learning_environment", "").lower()
            is_online = "온라인" in env_lower
            if "operator_guide" not in implementation_result:
                if is_online:
                    implementation_result["operator_guide"] = """1. 플랫폼 준비: 화상회의 링크 생성 및 배포, 녹화 설정 확인, 소그룹 세션 사전 구성, 대기실 설정
2. 참가자 관리: 접속 현황 모니터링, 접속 문제 지원, 채팅 관리, 출석 체크 및 기록
3. 기술 지원: 화면 공유 문제 해결, 음성 문제 지원, 백업 링크 준비, 네트워크 장애 대응
4. 사후 처리: 녹화본 편집 및 업로드, 출석 기록 정리, 설문 결과 수합, 참가자 이메일 발송"""
                else:
                    implementation_result["operator_guide"] = """1. 교육 환경 준비: 강의실 예약 확인, 장비 점검 (프로젝터, 마이크, PC), 학습 자료 인쇄 및 배치, 다과 준비
2. 참가자 관리: 출석 체크, 명찰 배부, 좌석 안내, 특이사항 기록
3. 운영 지원: 강사와 소통, 시간 관리, 휴식 시간 안내, 돌발 상황 대응
4. 사후 처리: 강의실 정리, 장비 반납, 설문 수합, 참석 현황 보고"""
            if "orientation_plan" not in implementation_result:
                if is_online:
                    implementation_result["orientation_plan"] = """1. 강사/진행자 오리엔테이션 (교육 3일 전): 플랫폼 기능 숙지, 화면 공유 테스트, 소그룹 세션 운영법 안내, 교수 자료 검토
2. 운영자 오리엔테이션 (교육 2일 전): 기술 지원 역할 설명, 문제 대응 매뉴얼 공유, 비상 연락망 확인, 체크리스트 배부
3. 리허설 (교육 1일 전): 전체 플로우 테스트, 백업 시나리오 점검, 시간 배분 확인, 최종 점검 완료"""
                else:
                    implementation_result["orientation_plan"] = """1. 강사/진행자 오리엔테이션 (교육 1주 전): 교육 목표 및 커리큘럼 설명, 교수 자료 전달 및 검토, 진행 방식 협의, Q&A
2. 운영자 오리엔테이션 (교육 3일 전): 운영 역할 및 책임 설명, 체크리스트 배부, 비상 연락망 공유, 리허설 일정 확인
3. 리허설 (교육 1일 전): 장비 테스트, 동선 확인, 시간 배분 점검, 최종 조율"""
            if "pilot_plan" not in implementation_result:
                implementation_result["pilot_plan"] = {
                    "pilot_scope": "1차 파일럿: 소규모 그룹(10-15명) 대상 전체 과정 시범 운영",
                    "participants": "각 부서 대표 1-2명, 교육 담당자 참관",
                    "duration": "본 교육과 동일",
                    "success_criteria": ["학습 목표 달성률 80% 이상", "만족도 4.0/5.0 이상", "주요 이슈 없이 진행"],
                    "data_collection": ["사전/사후 테스트 점수", "만족도 설문", "관찰 기록", "참가자 피드백"],
                    "contingency_plan": "기술적 문제 발생 시 백업 자료 활용, 시간 초과 시 선택적 모듈 축소",
                }

        # 2. 유지관리 계획 생성
        materials = development.get("materials", [])
        content_types = [m.get("type", "자료") for m in materials] if materials else ["슬라이드", "핸드아웃"]
        start_time = datetime.now()
        try:
            maintenance_result = create_maintenance_plan.invoke({
                "program_title": scenario.get("title", "교육 프로그램"),
                "delivery_method": implementation_result.get("delivery_method", context.get("learning_environment", "대면 교육")),
                "content_types": content_types,
                "update_frequency": "분기별",
            })
            tool_calls.append(self._record_tool_call(
                state, "create_maintenance_plan",
                {"program_title": scenario.get("title", "")},
                f"유지관리 계획 완료: {len(maintenance_result.get('content_maintenance', {}).get('update_triggers', []))}개 업데이트 트리거",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_maintenance_plan 실패: {str(e)}")
            maintenance_result = {}

        self._log(f"Implementation 완료: facilitator_guide={len(implementation_result.get('facilitator_guide', ''))}자, maintenance_plan={bool(maintenance_result)}")

        # 출력 구조 평탄화: 루브릭 항목과 일치하도록 필드를 phase 레벨로 이동
        # Item 24: 교수자·운영자 오리엔테이션
        # Item 25: 시스템/환경 점검 (technical_requirements에 포함)
        # Item 26: 프로토타입 실행 (pilot_plan)
        # Item 27: 운영 모니터링 및 지원 (support_plan)
        return {
            "implementation_result": {
                # 기존 implementation_plan 내용을 평탄화
                "delivery_method": implementation_result.get("delivery_method", ""),
                "facilitator_guide": implementation_result.get("facilitator_guide", ""),
                "learner_guide": implementation_result.get("learner_guide", ""),
                "technical_requirements": implementation_result.get("technical_requirements", []),
                "support_plan": implementation_result.get("support_plan", ""),
                # 루브릭 항목과 매칭되는 필드 (평탄화)
                "operator_guide": implementation_result.get("operator_guide", ""),  # Dev-21
                "instructor_operator_orientation": implementation_result.get("orientation_plan", ""),  # I-24
                "system_environment_check": {
                    "technical_requirements": implementation_result.get("technical_requirements", []),
                    "pre_check_items": ["플랫폼 접속 테스트", "학습 자료 업로드 확인", "네트워크 안정성 점검"],
                },  # I-25
                "prototype_execution": implementation_result.get("pilot_plan", {}),  # I-26
                "operation_monitoring": {
                    "monitoring_items": ["학습자 참여도", "기술적 이슈", "시간 준수"],
                    "support_channels": ["실시간 채팅", "Q&A 게시판", "이메일 지원"],
                    "escalation_process": "1차: 운영자 → 2차: 강사 → 3차: 관리자",
                },  # I-27
                # 유지관리 계획
                "maintenance_plan": maintenance_result,
            },
            "current_phase": "evaluation",
            "tool_calls": tool_calls,
            "reasoning_steps": reasoning_steps,
            "errors": errors,
        }

    def _evaluation_node(self, state: ADDIEState) -> dict:
        """Evaluation 단계 노드"""
        self._log("Evaluation 단계 시작")
        scenario = state["scenario"]
        analysis = state.get("analysis_result", {})
        design = state.get("design_result", {})
        task_analysis = analysis.get("task_analysis", {})
        tool_calls = state.get("tool_calls", [])
        reasoning_steps = state.get("reasoning_steps", [])
        errors = state.get("errors", [])

        reasoning_steps.append("Step 5: Evaluation 단계 - 퀴즈 문항, 평가 루브릭, 성과평가 계획 생성")

        objectives = design.get("learning_objectives", [])
        main_topics = task_analysis.get("main_topics", scenario.get("learning_goals", []))

        # 1. 퀴즈 문항 생성
        start_time = datetime.now()
        try:
            quiz_result = create_quiz_items.invoke({
                "objectives": objectives,
                "main_topics": main_topics,
                "difficulty": scenario.get("difficulty"),
                "num_items": 10,
            })
            tool_calls.append(self._record_tool_call(
                state, "create_quiz_items",
                {"objectives_count": len(objectives)},
                f"퀴즈 문항 생성 완료: {len(quiz_result)}개",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_quiz_items 실패: {str(e)}")
            quiz_result = []

        # 2. 평가 루브릭 생성
        start_time = datetime.now()
        try:
            rubric_result = create_rubric.invoke({
                "objectives": objectives,
                "assessment_type": "종합 평가",
            })
            tool_calls.append(self._record_tool_call(
                state, "create_rubric",
                {"objectives_count": len(objectives)},
                f"평가 루브릭 생성 완료: {len(rubric_result.get('criteria', []))}개 기준",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_rubric 실패: {str(e)}")
            rubric_result = {}

        # 3. 성과평가 계획 생성 (Kirkpatrick 4-Level)
        start_time = datetime.now()
        try:
            context = scenario.get("context", {})
            program_evaluation_result = create_program_evaluation.invoke({
                "program_title": scenario.get("title", "교육 프로그램"),
                "objectives": objectives,
                "target_audience": context.get("target_audience", "일반 학습자"),
            })
            tool_calls.append(self._record_tool_call(
                state, "create_program_evaluation",
                {"program_title": scenario.get("title", "")},
                f"성과평가 계획 완료: Kirkpatrick 4-Level 모델",
                start_time,
            ))
        except Exception as e:
            errors.append(f"create_program_evaluation 실패: {str(e)}")
            program_evaluation_result = {}

        self._log(f"Evaluation 완료: quiz_items={len(quiz_result)}, criteria={len(rubric_result.get('criteria', []))}, program_evaluation={bool(program_evaluation_result)}")

        # 출력 구조: 루브릭 항목과 일치하도록 명시적 필드명 사용
        # Item 28: 파일럿/초기 실행 중 자료 수집
        # Item 29: 형성평가 결과 기반 1차 프로그램 개선
        # Item 30: 총괄 평가 문항 개발
        # Item 31: 총괄평가 시행 및 프로그램 효과 분석
        # Item 32: 프로그램 채택 여부 결정
        # Item 33: 프로그램 개선

        # Item 28: 파일럿 실행 중 자료 수집 계획
        pilot_data_collection = {
            "collection_methods": [
                {"method": "사전/사후 테스트", "timing": "교육 시작 전/종료 후", "data_type": "학습 성취도"},
                {"method": "만족도 설문", "timing": "교육 종료 직후", "data_type": "학습자 만족도"},
                {"method": "관찰 기록", "timing": "교육 진행 중", "data_type": "참여도, 이해도"},
                {"method": "인터뷰/FGI", "timing": "교육 종료 1주 내", "data_type": "질적 피드백"},
            ],
            "analysis_plan": {
                "quantitative": "사전/사후 점수 비교, 만족도 평균, 참여율 산출",
                "qualitative": "피드백 주제 분석, 개선 요청 사항 분류",
            },
            "improvement_triggers": [
                "학습 목표 달성률 80% 미만 시 콘텐츠 수정",
                "만족도 4.0 미만 시 진행 방식 개선",
                "특정 모듈 이해도 낮을 시 보충 자료 추가",
            ],
        }

        # Item 29: 형성평가 결과 기반 1차 프로그램 개선
        formative_improvement = {
            "evaluation_criteria": rubric_result.get("criteria", []),
            "improvement_process": [
                "1. 파일럿 데이터 수집 및 분석",
                "2. 문제 영역 식별 및 우선순위 결정",
                "3. 개선안 도출 및 전문가 검토",
                "4. 수정본 적용 및 재검증",
            ],
            "feedback_integration": "학습자 피드백과 관찰 결과를 종합하여 콘텐츠 및 운영 방식 개선",
        }

        return {
            "evaluation_result": {
                "quiz_items": quiz_result,  # Item 30: 총괄 평가 문항
                "rubric": rubric_result,
                "program_evaluation": program_evaluation_result,  # Item 31, 32
                "feedback_plan": rubric_result.get("feedback_plan", "평가 후 개별 피드백 제공"),
                # 루브릭 항목과 매칭되는 필드 추가
                "pilot_data_collection": pilot_data_collection,  # Item 28
                "formative_improvement": formative_improvement,  # Item 29
            },
            "current_phase": "complete",
            "tool_calls": tool_calls,
            "reasoning_steps": reasoning_steps,
            "errors": errors,
        }

    def run(self, scenario: dict) -> dict:
        """
        시나리오를 입력받아 ADDIE 산출물을 생성합니다.

        Args:
            scenario: 시나리오 딕셔너리

        Returns:
            dict: 완전한 결과 (ADDIE + trajectory + metadata)
        """
        start_time = datetime.now()

        # 초기 상태 생성
        initial_state = create_initial_state(scenario)

        # StateGraph 실행
        final_state = self.graph.invoke(initial_state)

        # 메타데이터 생성
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        # ADDIE 출력 조립
        raw_output = {
            "analysis": final_state.get("analysis_result", {}),
            "design": final_state.get("design_result", {}),
            "development": final_state.get("development_result", {}),
            "implementation": final_state.get("implementation_result", {}),
            "evaluation": final_state.get("evaluation_result", {}),
        }

        # 표준 스키마로 변환
        addie_output = self._convert_to_standard_schema(raw_output)

        result = {
            "scenario_id": scenario.get("scenario_id", "unknown"),
            "agent_id": "addie-agent",
            "timestamp": end_time.isoformat(),
            "addie_output": addie_output,
            "trajectory": {
                "tool_calls": final_state.get("tool_calls", []),
                "reasoning_steps": final_state.get("reasoning_steps", []),
            },
            "metadata": {
                "model": self.model,
                "total_tokens": 0,
                "execution_time_seconds": execution_time,
                "agent_version": "0.1.0",
                "tool_calls_count": len(final_state.get("tool_calls", [])),
                "errors": final_state.get("errors", []),
            },
        }

        self._log(f"ADDIE 완료: {execution_time:.2f}초, {len(final_state.get('tool_calls', []))}개 도구 호출")

        return result

    def _convert_to_standard_schema(self, raw: dict) -> dict:
        """
        내부 ADDIE 구조를 표준 스키마로 변환합니다.

        표준 스키마 (docs/addie_output_schema.json) 준수
        """
        # Analysis 변환
        a = raw.get("analysis", {})
        na = a.get("needs_analysis", {})
        la = a.get("learner_analysis", {})
        ca = a.get("context_analysis", {})
        ta = a.get("task_analysis", {})

        # problem_definition 생성 (항목 1)
        problem_def = na.get("problem_definition", "") or na.get("performance_gap", "")
        if not problem_def:
            current = na.get("current_state", "현재 역량 부족")
            desired = na.get("desired_state", "목표 역량 달성")
            problem_def = f"현재 상태: {current}. 목표 상태: {desired}. 이 차이를 해소하기 위한 교육적 개입이 필요함."

        analysis_dict = {
            "needs_analysis": {
                "problem_definition": problem_def,
                "gap_analysis": na.get("gap_analysis", []) if isinstance(na.get("gap_analysis"), list) else [
                    {"current": na.get("current_state", ""), "target": na.get("desired_state", ""), "gap": na.get("performance_gap", "")}
                ],
                "performance_analysis": f"교육 니즈: {', '.join((na.get('training_needs') or [])[:3])}. 비교육 솔루션: {', '.join((na.get('non_training_solutions') or [])[:2])}",
                "priority_matrix": na.get("priority_matrix", {}),
            },
            "learner_analysis": {
                "target_audience": la.get("target_audience", ""),
                "characteristics": la.get("characteristics", []),
                "prior_knowledge": la.get("prior_knowledge", ""),
                "learning_preferences": la.get("learning_preferences", []),
                "motivation": la.get("motivation", ""),
            },
            "context_analysis": {
                "environment": ca.get("environment", ""),
                "constraints": ca.get("constraints", []),
                "resources": ca.get("resources", []),
                "technical_requirements": ca.get("technical_requirements", []),
            },
            "task_analysis": {
                "initial_objectives": ta.get("main_topics", []),
                "subtopics": ta.get("subtopics", []),
                "prerequisites": ta.get("prerequisites", []),
                "review_summary": ta.get("review_summary", "") or f"주제: {', '.join(ta.get('main_topics', [])[:3])}",
            },
        }

        # Design 변환
        d = raw.get("design", {})
        ist = d.get("instructional_strategy", {})

        # 학습 활동 생성
        learning_activities = []
        for event in ist.get("sequence", []):
            learning_activities.append({
                "activity_name": event.get("event", ""),
                "duration": event.get("duration", ""),
                "description": event.get("activity", ""),
                "materials": event.get("resources", []),
            })

        design_dict = {
            "learning_objectives": d.get("learning_objectives", []),
            "assessment_plan": {
                "formative": [{"description": f} for f in d.get("assessment_plan", {}).get("formative", [])],
                "summative": [{"description": s} for s in d.get("assessment_plan", {}).get("summative", [])],
                "assessment_criteria": d.get("assessment_plan", {}).get("diagnostic", []),
            },
            "content_structure": {
                "modules": [m.get("title", "") for m in raw.get("development", {}).get("lesson_plan", {}).get("modules", [])],
                "topics": ta.get("main_topics", []),
                "sequencing": ist.get("model", ""),
            },
            "instructional_strategies": {
                "methods": ist.get("methods", []),
                "activities": [e.get("activity", "") for e in ist.get("sequence", [])[:5]],
                "rationale": f"모델: {ist.get('model', '')}",
            },
            "non_instructional_strategies": {
                "motivation_strategies": [],
                "self_directed_learning": [],
                "support_strategies": [],
            },
            "media_selection": {
                "media_types": [],
                "tools": [],
                "utilization_plan": "",
            },
            "learning_activities": learning_activities,
            "storyboard": {
                "screens": [
                    {"screen_id": "S01", "title": "도입", "description": "학습 목표 및 개요 소개"},
                    {"screen_id": "S02", "title": "학습 내용", "description": "핵심 개념 및 내용 제시"},
                    {"screen_id": "S03", "title": "실습/활동", "description": "학습자 참여 활동"},
                    {"screen_id": "S04", "title": "평가", "description": "학습 성취도 확인"},
                    {"screen_id": "S05", "title": "마무리", "description": "요약 및 다음 단계 안내"},
                ],
                "navigation_flow": "S01 → S02 → S03 → S04 → S05 (순차 진행, 이전/다음 버튼)",
                "interactions": ["클릭", "드래그앤드롭", "텍스트 입력", "선택형 퀴즈"],
            },
        }

        # Development 변환
        dev = raw.get("development", {})
        impl = raw.get("implementation", {})

        # learner_materials 변환
        learner_materials = []
        for mat in dev.get("learner_materials", []) or dev.get("materials", []):
            learner_materials.append({
                "title": mat.get("title", ""),
                "type": mat.get("type", ""),
                "content": mat.get("description", "") or mat.get("content", ""),
                "format": "PDF/PPT",
            })
        # 기본값 보장 (Item 19: 학습자용 자료 개발)
        if not learner_materials:
            learner_materials = [
                {"title": "학습 가이드", "type": "문서", "content": "학습 목표, 진행 방법, 평가 기준을 포함한 학습자용 가이드", "format": "PDF"},
                {"title": "워크시트", "type": "활동자료", "content": "학습 내용 적용을 위한 실습 워크시트", "format": "PDF"},
                {"title": "참고자료", "type": "보조자료", "content": "심화 학습을 위한 추가 참고자료 및 링크", "format": "PDF/Web"},
            ]

        # quiz_items를 assessment_tools로 변환
        ev = raw.get("evaluation", {})
        quiz_tools = [
            {
                "item_id": q.get("id", f"Q-{idx+1:03d}"),
                "type": q.get("type", ""),
                "question": q.get("question", ""),
                "aligned_objective": q.get("objective_id", ""),
                "scoring_criteria": q.get("explanation", ""),
            }
            for idx, q in enumerate(ev.get("quiz_items", []))
        ]

        development_dict = {
            "learner_materials": learner_materials,
            "instructor_guide": {
                "overview": impl.get("facilitator_guide", ""),
                "session_guides": [mod.get("title", "") for mod in dev.get("lesson_plan", {}).get("modules", [])],
                "facilitation_tips": ["학습자 참여 유도", "질문 활용"],
                "troubleshooting": ["기술적 문제 대응"],
            },
            "operator_manual": {
                "system_setup": impl.get("operator_guide", ""),
                "operation_procedures": ["등록 관리", "출석 관리"],
                "support_procedures": ["학습자 문의 대응"],
                "escalation_process": "문제 발생 시 담당자에게 보고",
            },
            "assessment_tools": quiz_tools,
            "expert_review": {
                "reviewers": ["내용 전문가", "교수설계 전문가", "현장 전문가"],
                "review_criteria": ["내용 정확성", "교수 설계 적절성", "학습 목표 정렬", "학습자 수준 적합성"],
                "feedback_summary": "전문가 검토 결과 내용의 정확성과 교수 설계의 적절성이 확인되었으며, 학습 목표와의 정렬 및 학습자 수준 적합성에 대한 피드백을 반영하여 개선 작업을 진행함",
                "revisions_made": ["전문가 피드백 기반 콘텐츠 수정", "학습 목표 정렬 강화", "학습자 수준에 맞는 예시 추가"],
            },
        }

        # Implementation 변환
        op = impl.get("instructor_operator_orientation", "") or impl.get("orientation_plan", {})
        sc = impl.get("system_environment_check", {})
        pp = impl.get("prototype_execution", {})
        mp = impl.get("operation_monitoring", {})

        implementation_dict = {
            "instructor_orientation": {
                "orientation_objectives": ["프로그램 이해", "운영 절차 숙지"],
                "schedule": op if isinstance(op, str) else str(op),
                "materials": ["교수자 가이드", "운영 매뉴얼"],
                "competency_checklist": ["내용 이해도", "진행 능력"],
            },
            "system_check": {
                "checklist": sc.get("pre_check_items", impl.get("technical_requirements", [])),
                "technical_validation": "시스템 테스트 완료",
                "contingency_plans": ["비상 대응 계획 수립"],
            },
            "prototype_execution": {
                "pilot_scope": pp.get("pilot_scope", "") if isinstance(pp, dict) else "소규모 파일럿 테스트",
                "participants": pp.get("participants", "") if isinstance(pp, dict) else "10명 내외",
                "execution_log": pp.get("data_collection", []) if isinstance(pp, dict) else [],
                "issues_encountered": [],
            },
            "monitoring": {
                "monitoring_criteria": mp.get("monitoring_items", ["학습 진도", "참여율"]),
                "support_channels": mp.get("support_channels", ["이메일", "전화"]),
                "issue_resolution_log": [],
                "real_time_adjustments": [],
            },
        }

        # Evaluation 변환
        pdc = ev.get("pilot_data_collection", {})
        fi = ev.get("formative_improvement", {})
        pe = ev.get("program_evaluation", {})
        rubric = ev.get("rubric", {})

        # 항목 28: 데이터 수집 기본값
        data_collection_methods = [m.get("method", "") for m in pdc.get("collection_methods", [])]
        if not data_collection_methods:
            data_collection_methods = ["사전/사후 테스트", "만족도 설문", "관찰 기록", "인터뷰"]

        # 항목 29: 형성평가 개선 기본값
        improvement_steps = fi.get("improvement_process", [])
        if not improvement_steps:
            improvement_steps = [
                "파일럿 데이터 분석 및 문제점 식별",
                "개선 우선순위 결정 및 수정안 도출",
                "전문가 검토 후 수정본 적용",
                "재검증 및 최종 반영",
            ]

        # 항목 31: 효과성 분석 기본값
        kirk_analysis = pe.get("kirkpatrick_analysis", {})
        learning_outcomes = kirk_analysis.get("level1_reaction", {})
        if not learning_outcomes:
            learning_outcomes = {
                "description": "학습자 반응 평가",
                "methods": ["만족도 설문"],
                "target_score": "4.0/5.0 이상",
            }

        goal_achievement = pe.get("effectiveness_score", "")
        if not goal_achievement:
            goal_achievement = "목표 달성률 80% 이상 예상"

        # 항목 32: 채택 결정 기본값
        adoption_decision_val = pe.get("adoption_recommendation", "")
        adoption_rationale = pe.get("rationale", "")
        if not adoption_decision_val:
            adoption_decision_val = "조건부 채택"
            adoption_rationale = "파일럿 결과에 따라 최종 결정. 학습 목표 달성률 및 만족도 기준 충족 시 본격 도입."

        # 항목 33: 개선 계획 기본값
        feedback_summary = ev.get("feedback_plan", "")
        if not feedback_summary:
            feedback_summary = "학습자 피드백과 평가 결과를 종합하여 프로그램 개선에 반영"

        improvement_areas = fi.get("evaluation_criteria", rubric.get("criteria", []))
        if not improvement_areas:
            improvement_areas = ["학습 내용 적절성", "전달 방식 효과성", "평가 도구 타당성"]

        action_items = fi.get("improvement_process", [])
        if not action_items:
            action_items = ["콘텐츠 업데이트", "교수 방법 개선", "평가 문항 보완"]

        evaluation_dict = {
            "formative": {
                "data_collection": {
                    "methods": data_collection_methods,
                    "learner_feedback": pdc.get("analysis_plan", {}).get("qualitative", "") or ["학습자 의견 수집", "어려운 부분 피드백", "개선 요청 사항"],
                    "performance_data": pdc.get("analysis_plan", {}) or {"quantitative": "사전/사후 점수 비교", "qualitative": "피드백 분석"},
                    "observations": pdc.get("improvement_triggers", []) or ["학습 진행 관찰", "참여도 모니터링", "학습자 행동 패턴 분석"],
                    "pilot_difficulties": {
                        "identified_modules": ["개념 이해 모듈", "실습 적용 모듈"],
                        "difficulty_reasons": ["선수 지식 부족", "실습 시간 부족", "자료 복잡성"],
                        "improvement_suggestions": ["보충 자료 제공", "실습 시간 확대", "단계별 가이드 추가"],
                    },
                },
                "improvements": [
                    {
                        "issue_identified": step,
                        "improvement_action": "개선 조치 실행",
                        "priority": "높음" if idx == 0 else "보통",
                    }
                    for idx, step in enumerate(improvement_steps)
                ],
            },
            "summative": {
                "assessment_tools": quiz_tools,
                "effectiveness_analysis": {
                    "learning_outcomes": learning_outcomes,
                    "goal_achievement_rate": goal_achievement,
                    "statistical_analysis": str(kirk_analysis.get("level2_learning", "")) or "사전/사후 점수 t-검정 분석",
                    "recommendations": pe.get("recommendations", []) or ["지속적인 개선 권고"],
                },
                "adoption_decision": {
                    "decision": adoption_decision_val,
                    "rationale": adoption_rationale,
                    "conditions": pe.get("conditions", []) or ["파일럿 결과 양호", "예산 확보"],
                    "stakeholder_approval": "승인 대기",
                },
            },
            "improvement_plan": {
                "feedback_summary": feedback_summary,
                "improvement_areas": improvement_areas,
                "action_items": action_items,
                "feedback_loop": fi.get("feedback_integration", "평가 결과를 바탕으로 다음 교육 과정에 반영"),
                "next_iteration_goals": pe.get("next_steps", []) or ["프로그램 안정화", "확대 적용 검토"],
            },
        }

        return {
            "analysis": analysis_dict,
            "design": design_dict,
            "development": development_dict,
            "implementation": implementation_dict,
            "evaluation": evaluation_dict,
        }
