{
  "scenario_id": "BAL-LARGE2-1574",
  "variant_type": "balance_large_scale_v2",
  "title": "Large-Scale Workshop on Regularization Techniques for Neural Network Structure Optimization",
  "context": {
    "prior_knowledge": "Understanding of fundamental machine learning concepts and experience with Python programming",
    "duration": "Mid-term course (2-4 weeks)",
    "learning_environment": "Offline (classroom)",
    "class_size": "Large (30+ learners)",
    "additional_context": "Performing simple neural network simulations using smartphone-based practical tools",
    "institution_type": "Corporate/Enterprise",
    "learner_age": "Teens (13-19)",
    "learner_education": "Adult learner (non-degree)",
    "learner_role": "Professional (medical/legal/technical)",
    "domain_expertise": "Intermediate"
  },
  "learning_goals": [
    "Learners can explain the principles of inactive/linear unit generation in neural networks and analyze them using diagnostic tools.",
    "Learners can improve the accuracy of simple ReLU networks with three or fewer layers by 15% or more by applying Jumpstart regularization techniques.",
    "Learners can write model performance analysis reports using four evaluation metrics: Dead Units, Linear Units, Trainability, and Convergence."
  ],
  "constraints": {
    "budget": "low",
    "resources": [
      "Tablet PC rental set",
      "Offline Neural Network Simulation Kit",
      "Printed learning materials",
      "USB Memory-Based Dataset"
    ],
    "accessibility": null,
    "language": "en",
    "tech_requirements": "Limited tech environment (no PC, smartphone only)",
    "assessment_type": "Formative assessment-focused"
  },
  "difficulty": "Moderate - Standard complexity with some constraints",
  "domain": "Medical/Nursing"
}